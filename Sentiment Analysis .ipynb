{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from wordcloud import WordCloud\n",
    "import xgboost as xgb\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.DataFrame()\n",
    "for dirname,_,filenames in os.walk(\"C:\\\\Users\\\\maria\\\\Desktop\\\\sentiment labelled sentences\"):\n",
    "    for filename in filenames:\n",
    "        if(filename.endswith(\".txt\")):\n",
    "            data_df = data_df.append(pd.read_csv(os.path.join(dirname,filename),delimiter='\\t',header=None,names=[\"Review\",\"Sentiment\"]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2769"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.reset_index(drop=\"True\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Review']=data_df['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case, excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  so there is no way for me to plug it in here i...        0.0\n",
       "1                        good case, excellent value.        1.0\n",
       "2                             great for the jawbone.        1.0\n",
       "3  tied to charger for conversations lasting more...        0.0\n",
       "4                                  the mic is great.        1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Review']=data_df['Review'].str.replace(\"[^a-zA-z]\",\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Review']=data_df['Review'].apply(lambda x:' '.join([words for words in x.split() if len(words)>=3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there way for plug here the unless converter</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied charger for conversations lasting more th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic great</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0       there way for plug here the unless converter        0.0\n",
       "1                          good case excellent value        1.0\n",
       "2                              great for the jawbone        1.0\n",
       "3  tied charger for conversations lasting more th...        0.0\n",
       "4                                      the mic great        1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>way plug unless converter</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great jawbone</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied charger conversations lasting minutes maj...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mic great</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0                          way plug unless converter        0.0\n",
       "1                          good case excellent value        1.0\n",
       "2                                      great jawbone        1.0\n",
       "3  tied charger conversations lasting minutes maj...        0.0\n",
       "4                                          mic great        1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Review']=data_df['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>way plug unless convert</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excel valu</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great jawbon</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tie charger convers last minut major problem</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mic great</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review  Sentiment\n",
       "0                       way plug unless convert        0.0\n",
       "1                          good case excel valu        1.0\n",
       "2                                  great jawbon        1.0\n",
       "3  tie charger convers last minut major problem        0.0\n",
       "4                                     mic great        1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "stemmer=SnowballStemmer('english')\n",
    "\n",
    "data_df['Review']=data_df['Review'].apply(lambda x: ' '.join([stemmer.stem(lemma.lemmatize(word)) for word in x.split()]))\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109112"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = ' '.join([words for words in data_df['Review']])\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = ' '.join([words for words in data_df[data_df['Sentiment']==1]['Review']])\n",
    "len(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words = ' '.join([words for words in data_df[data_df['Sentiment']==0]['Review']])\n",
    "len(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a9052291ceab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_font_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "wordcloud = WordCloud(width=1000,height=500,random_state=21, max_font_size=110).generate(all_words)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt  \n",
    "wordcloud = WordCloud(width=1000, height=500, random_state=21, max_font_size=110).generate(positive_words) \n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud=WordCloud(width=1000, height=500, random_state=21, max_font_size=110).generate(negative_words)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate rare and frequently occuring words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424433, 537600)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models\n",
    "tokenized = data_df['Review'].apply(lambda x: x.split())\n",
    "model_w2v = models.Word2Vec(tokenized,min_count=2,vector_size=500,alpha=0.03, \n",
    "                     min_alpha=0.0007)\n",
    "model_w2v.build_vocab(tokenized,progress_per=10000)\n",
    "model_w2v.train(tokenized, total_examples=model_w2v.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slow', 0.99055415391922),\n",
       " ('littl', 0.9891200065612793),\n",
       " ('mediocr', 0.9882552027702332),\n",
       " ('serv', 0.9859213829040527),\n",
       " ('attitud', 0.9858940243721008),\n",
       " ('fantast', 0.9858649969100952),\n",
       " ('non', 0.9854453802108765),\n",
       " ('prepar', 0.9854159951210022),\n",
       " ('apolog', 0.9853435158729553),\n",
       " ('basic', 0.9850645065307617),\n",
       " ('toward', 0.9847434759140015),\n",
       " ('extrem', 0.9846440553665161),\n",
       " ('talk', 0.9846248030662537),\n",
       " ('charisma', 0.9842594265937805),\n",
       " ('atroci', 0.9842436909675598),\n",
       " ('focus', 0.9838920831680298),\n",
       " ('pace', 0.9837925434112549),\n",
       " ('par', 0.9837725162506104),\n",
       " ('pay', 0.9837449193000793),\n",
       " ('pass', 0.9837180376052856),\n",
       " ('sprint', 0.983699381351471),\n",
       " ('meh', 0.9836912155151367),\n",
       " ('aw', 0.9836273789405823),\n",
       " ('averag', 0.9834861159324646),\n",
       " ('delici', 0.9834702014923096)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive=['terribl'],topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700787"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.similarity('horribl','terribl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.doesnt_match(['good','horribl','terribl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.74120843e-01,  1.74319312e-01,  1.43234730e-01,  1.59020826e-01,\n",
       "       -2.49292124e-02, -1.42647564e-01, -8.55142530e-03,  1.99307442e-01,\n",
       "        4.58303839e-02,  4.19029444e-02, -3.36616822e-02,  7.93639719e-02,\n",
       "        2.72114333e-02,  3.66062298e-02,  4.22327220e-02, -1.40021607e-01,\n",
       "       -1.70206085e-01, -8.25625472e-03,  1.27335787e-02,  3.91234607e-02,\n",
       "        1.14053033e-01, -5.68280555e-02,  1.16813660e-01, -3.92387956e-02,\n",
       "        9.80603471e-02,  5.48830293e-02,  7.10215196e-02,  4.38689766e-03,\n",
       "       -2.44485706e-01, -1.77769677e-03,  4.31259274e-02, -3.47218290e-02,\n",
       "       -9.08817425e-02, -4.77706976e-02,  1.72455460e-01,  9.39952806e-02,\n",
       "        2.70367004e-02, -1.35579303e-01, -4.81237993e-02, -1.45756096e-01,\n",
       "        1.11813666e-02, -5.94368950e-02, -1.68569475e-01,  1.01409614e-01,\n",
       "       -9.07056704e-02, -9.24823284e-02, -8.00895095e-02,  4.78515700e-02,\n",
       "       -4.14728634e-02, -1.59983914e-02, -2.03076396e-02, -1.61702223e-02,\n",
       "       -3.88611183e-02, -2.18066856e-01, -2.17506085e-02, -6.38645291e-02,\n",
       "        1.14342332e-01,  3.21965739e-02, -3.79178300e-02,  4.86981943e-02,\n",
       "        2.79137027e-03, -3.62681188e-02, -8.87011271e-03,  2.56664101e-02,\n",
       "       -4.01668288e-02,  4.46848273e-02, -1.02166377e-01,  3.03164441e-02,\n",
       "        7.83869177e-02, -2.32141372e-02, -5.68115972e-02,  4.76931222e-02,\n",
       "        4.03232919e-03, -1.82557423e-02,  9.26332995e-02,  1.42364353e-01,\n",
       "       -9.60540995e-02, -8.07530284e-02,  4.38323282e-02,  8.57352540e-02,\n",
       "       -1.25014603e-01, -4.61018868e-02, -9.77887139e-02,  1.55434757e-01,\n",
       "       -2.71583736e-01,  9.62763131e-02, -6.51596114e-02,  9.36558917e-02,\n",
       "        1.29300296e-01,  1.82696074e-01, -8.38924292e-03,  3.05669736e-02,\n",
       "       -8.35562721e-02,  8.34928751e-02,  4.94827516e-03,  8.83509964e-02,\n",
       "        1.04896933e-01,  1.40896756e-02,  8.49681497e-02,  6.66162744e-02,\n",
       "       -1.38841629e-01, -4.41941805e-03, -6.56252131e-02,  1.70630857e-01,\n",
       "        8.04248080e-02,  2.45011896e-02, -8.56403559e-02,  1.94092572e-01,\n",
       "       -7.85666332e-02, -4.47850861e-03, -1.26770571e-01, -1.61268190e-01,\n",
       "       -1.01010948e-02,  1.53237030e-01, -8.15173164e-02,  5.55347875e-02,\n",
       "        4.56678122e-02, -1.67302310e-01,  6.53737187e-02, -8.76631662e-02,\n",
       "        2.77087726e-02,  1.08060185e-02,  1.30745664e-01,  9.67833493e-03,\n",
       "        2.29746476e-02,  1.36014875e-02, -1.43330112e-01,  5.78119159e-02,\n",
       "       -5.16876392e-02,  7.00964704e-02,  1.80049792e-01,  1.24409795e-01,\n",
       "        6.25823741e-04, -3.40037607e-02, -3.41442239e-04,  1.33047417e-01,\n",
       "        3.07893530e-02, -5.81764467e-02, -1.99270695e-01, -2.70805180e-01,\n",
       "        3.17292660e-02, -1.02636747e-01,  5.95166311e-02, -1.58127844e-02,\n",
       "        4.55582365e-02,  2.52961479e-02,  6.54711723e-02, -1.25089094e-01,\n",
       "        1.15129702e-01,  1.18772075e-01,  6.03195615e-02, -1.38886282e-02,\n",
       "       -3.96633297e-02,  1.99726939e-01, -2.51618564e-01,  4.65319678e-02,\n",
       "        1.07034557e-01, -1.35535628e-01, -9.69510600e-02,  4.84435307e-03,\n",
       "        8.75331834e-02,  4.31561172e-02, -1.39854118e-01, -8.73360112e-02,\n",
       "       -6.21439628e-02,  6.88239411e-02,  1.76558778e-01,  6.39872104e-02,\n",
       "        9.30096805e-02,  1.19006634e-01,  1.02664717e-01,  1.12039402e-01,\n",
       "        4.22795787e-02,  1.18923903e-01, -2.32455507e-02, -6.82790950e-02,\n",
       "        5.38619719e-02,  3.87757807e-03,  9.59111657e-03,  8.96984190e-02,\n",
       "        3.29296850e-02, -5.38042374e-03,  4.45354842e-02,  1.27349980e-03,\n",
       "       -6.08869120e-02, -6.48188815e-02, -2.39553422e-01,  1.04419708e-01,\n",
       "       -9.85872000e-02,  6.03184327e-02,  1.91476896e-01, -9.88266617e-02,\n",
       "        1.17148399e-01,  1.35233840e-02,  1.05602741e-02,  4.50942777e-02,\n",
       "        2.32238732e-02, -9.61445943e-02,  8.76396522e-02,  7.03473538e-02,\n",
       "       -8.92386436e-02,  4.01660576e-02,  2.28792652e-01, -1.50641389e-02,\n",
       "        7.47008994e-02,  2.50685471e-03,  4.39071693e-02, -2.76297238e-02,\n",
       "       -1.72600389e-01, -4.12732214e-02, -4.46574241e-02, -1.44608065e-01,\n",
       "       -1.21505558e-01, -3.72494236e-02,  2.87804939e-02, -1.86750039e-01,\n",
       "       -7.77647942e-02, -7.55199557e-03, -1.04982704e-02, -1.51555941e-01,\n",
       "        8.36158618e-02,  1.48639321e-01,  6.25718236e-02,  1.91102792e-02,\n",
       "        2.80640405e-02, -2.38939468e-02,  1.26421988e-01, -1.35257199e-01,\n",
       "       -2.27216678e-03, -1.51324784e-02, -5.60986102e-02, -5.49679287e-02,\n",
       "       -4.39308994e-02, -6.02420866e-02, -3.89433838e-02, -4.29195911e-02,\n",
       "        2.43698172e-02, -2.13739082e-01,  1.51013002e-01, -6.52030557e-02,\n",
       "       -3.67514379e-02, -7.59477168e-02, -1.91812128e-01,  1.03531033e-01,\n",
       "       -5.50863706e-02, -9.09149051e-02,  6.69596642e-02,  5.05353585e-02,\n",
       "        5.21861836e-02,  1.16837524e-01,  1.57150719e-02, -2.56473303e-01,\n",
       "        1.73461419e-02, -2.93314699e-02, -6.15336038e-02,  1.48232624e-01,\n",
       "        2.31598616e-02,  1.67328328e-01, -2.23279119e-01,  8.58827755e-02,\n",
       "       -1.47496536e-01,  9.88948420e-02, -1.70933276e-01, -3.30668525e-03,\n",
       "        9.49111357e-02,  1.48923248e-02, -1.89905167e-01,  1.55426890e-01,\n",
       "       -1.98346019e-01, -2.76365243e-02, -8.96846652e-02,  6.47997260e-02,\n",
       "        1.72638401e-01, -8.16586018e-02, -6.75154626e-02,  1.31263798e-02,\n",
       "       -6.01612329e-02, -5.47028966e-02, -6.37613386e-02,  1.17544010e-01,\n",
       "        1.96058827e-04,  7.41494074e-02, -8.44326466e-02, -9.73919034e-02,\n",
       "        3.07411671e-01, -1.38784215e-01,  3.22833806e-02, -7.53725171e-02,\n",
       "        3.94615345e-02, -2.61874441e-02, -3.26655693e-02,  1.87121838e-01,\n",
       "        1.23940364e-01, -2.14192066e-02,  8.64680409e-02,  5.10473810e-02,\n",
       "        1.38299048e-01, -2.21095636e-01,  1.14511795e-01, -3.56435478e-02,\n",
       "       -5.62987477e-02, -2.51871217e-02,  2.31993068e-02, -2.34434847e-02,\n",
       "        3.14969085e-02, -8.49582851e-02, -2.69140024e-02,  1.25266537e-01,\n",
       "        4.44064662e-02, -5.07052168e-02, -7.81908706e-02, -1.18887462e-01,\n",
       "       -4.62458329e-03,  1.84763178e-01,  8.70339945e-02,  4.06866930e-02,\n",
       "        8.20645019e-02, -9.13652480e-02,  5.16903140e-02,  1.80324540e-02,\n",
       "        2.08404005e-01, -2.19968725e-02, -3.10444180e-03, -7.68804476e-02,\n",
       "        1.77994929e-02, -1.40734166e-01, -5.63538484e-02, -1.44377828e-01,\n",
       "        8.83880183e-02, -5.26738800e-02,  9.06551555e-02,  5.97942993e-02,\n",
       "       -2.97535118e-02,  5.10240272e-02,  3.22106928e-02, -1.43361568e-01,\n",
       "        5.63980676e-02,  1.03466302e-01,  5.70367882e-03, -9.43538994e-02,\n",
       "       -5.53691387e-02, -1.35934968e-02,  1.87252373e-01, -1.56918213e-01,\n",
       "       -1.04356140e-01, -5.54248504e-02, -3.08034897e-01,  7.38682523e-02,\n",
       "        5.28409891e-02,  1.34141386e-01, -8.25993996e-03,  9.75030661e-02,\n",
       "       -1.58533618e-01,  2.04172909e-01, -1.61392167e-01,  1.12985522e-01,\n",
       "       -1.16527908e-01, -3.29531580e-02,  7.85246119e-02,  3.80829014e-02,\n",
       "        1.46585563e-02,  8.04345459e-02, -4.09016805e-03,  5.90523668e-02,\n",
       "       -3.75502929e-02,  2.56060790e-02,  1.18906312e-01, -9.36281905e-02,\n",
       "       -1.44719958e-01,  1.55307308e-01,  7.41099045e-02, -1.56059474e-01,\n",
       "       -7.84931853e-02, -1.07559726e-01, -4.35993634e-02, -9.60403755e-02,\n",
       "        2.55646743e-02,  3.01947910e-02, -3.44283618e-02, -5.14621623e-02,\n",
       "        7.96084851e-02, -4.31309417e-02,  1.78979948e-01,  4.12321799e-02,\n",
       "        3.82781774e-02,  1.65762566e-02, -9.64318123e-03,  8.42849612e-02,\n",
       "       -1.22994650e-02, -8.36906489e-04, -2.80453078e-03, -4.49522361e-02,\n",
       "       -9.89469364e-02, -4.84225452e-02,  1.37113616e-01,  1.81450620e-01,\n",
       "       -1.52289281e-02, -1.05849765e-01, -5.81297129e-02,  1.46458462e-01,\n",
       "       -5.29380031e-02,  8.27355683e-02, -9.45452899e-02, -2.43991643e-01,\n",
       "       -2.82847080e-02, -1.50421754e-01, -1.44286584e-02,  3.70990634e-02,\n",
       "        9.23107639e-02,  1.62655264e-02, -4.09837663e-02, -2.05902636e-01,\n",
       "       -9.96915177e-02, -7.25436136e-02,  4.42609377e-02,  1.66297276e-02,\n",
       "        1.88829049e-01, -6.61989897e-02,  1.08073384e-01, -1.40152559e-01,\n",
       "       -7.56972507e-02,  8.15302506e-02, -9.49611813e-02,  6.53398708e-02,\n",
       "       -5.23211360e-02,  6.05153479e-03,  2.02108920e-03, -5.69469966e-02,\n",
       "       -1.35193661e-01, -1.17206231e-01, -1.02307655e-01,  4.97399531e-02,\n",
       "        3.66885252e-02, -6.69904202e-02, -3.86429876e-02,  4.90094274e-02,\n",
       "        3.25665399e-02, -4.25634235e-02, -9.21713486e-02,  7.60665759e-02,\n",
       "        1.60612620e-03, -3.95761169e-02,  1.34709641e-01,  2.73517948e-02,\n",
       "        2.31334567e-01,  5.01166284e-02,  9.08192545e-02,  7.06932694e-02,\n",
       "       -1.49927661e-01, -7.54189938e-02,  3.61460671e-02, -3.84997716e-03,\n",
       "       -4.88631614e-02, -2.15870932e-01, -3.76816392e-02, -4.74217832e-02,\n",
       "        1.29557624e-01, -3.74562889e-02,  2.62934174e-02, -5.64226136e-02,\n",
       "        1.26597121e-01,  3.69759649e-02, -1.04073510e-01,  5.93208745e-02,\n",
       "       -1.40715227e-01, -5.04977740e-02, -1.07525162e-01, -2.93474436e-01,\n",
       "       -8.49947184e-02,  1.19432718e-01, -1.08174890e-01, -4.27989988e-03,\n",
       "        6.46161139e-02, -1.53659835e-01,  1.62383065e-01,  2.14206472e-01,\n",
       "        1.55243814e-01,  2.26255152e-02, -1.79714233e-01, -1.26215234e-01,\n",
       "       -6.69057444e-02, -1.26777723e-01, -4.76804599e-02,  1.43941417e-01,\n",
       "        6.63072169e-02,  1.39221236e-01, -4.20266204e-02,  1.48774013e-01,\n",
       "        1.07646361e-01, -5.34294657e-02,  4.49066609e-02, -6.21371232e-02,\n",
       "        1.59616321e-01, -5.30654751e-02,  1.00785971e-03, -5.82255311e-02,\n",
       "       -2.34330464e-02, -1.20102860e-01, -4.64844182e-02, -7.55988136e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv['good']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature set for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v.wv[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2769, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized), 500)) \n",
    "for i in range(len(tokenized)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized[i], 500)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.116164</td>\n",
       "      <td>0.150140</td>\n",
       "      <td>0.157637</td>\n",
       "      <td>0.167075</td>\n",
       "      <td>-0.038732</td>\n",
       "      <td>-0.195063</td>\n",
       "      <td>-0.037403</td>\n",
       "      <td>0.224993</td>\n",
       "      <td>0.061536</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>-0.051435</td>\n",
       "      <td>0.164655</td>\n",
       "      <td>-0.029094</td>\n",
       "      <td>0.072818</td>\n",
       "      <td>-0.037900</td>\n",
       "      <td>-0.047797</td>\n",
       "      <td>-0.140069</td>\n",
       "      <td>-0.112368</td>\n",
       "      <td>-0.064705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161522</td>\n",
       "      <td>0.152545</td>\n",
       "      <td>0.123183</td>\n",
       "      <td>0.146035</td>\n",
       "      <td>-0.009645</td>\n",
       "      <td>-0.130634</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.188009</td>\n",
       "      <td>0.064717</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042883</td>\n",
       "      <td>-0.066830</td>\n",
       "      <td>0.183888</td>\n",
       "      <td>-0.068949</td>\n",
       "      <td>0.019747</td>\n",
       "      <td>-0.037597</td>\n",
       "      <td>-0.015067</td>\n",
       "      <td>-0.122631</td>\n",
       "      <td>-0.028011</td>\n",
       "      <td>-0.070028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.151950</td>\n",
       "      <td>0.117054</td>\n",
       "      <td>0.097127</td>\n",
       "      <td>0.124619</td>\n",
       "      <td>-0.027188</td>\n",
       "      <td>-0.105692</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.152977</td>\n",
       "      <td>0.043762</td>\n",
       "      <td>0.030666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>-0.054562</td>\n",
       "      <td>0.149631</td>\n",
       "      <td>-0.061866</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>-0.045131</td>\n",
       "      <td>-0.006541</td>\n",
       "      <td>-0.095804</td>\n",
       "      <td>-0.034160</td>\n",
       "      <td>-0.059227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097068</td>\n",
       "      <td>0.135354</td>\n",
       "      <td>0.151290</td>\n",
       "      <td>0.133517</td>\n",
       "      <td>-0.018089</td>\n",
       "      <td>-0.183336</td>\n",
       "      <td>-0.046367</td>\n",
       "      <td>0.208999</td>\n",
       "      <td>0.050225</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007296</td>\n",
       "      <td>-0.035852</td>\n",
       "      <td>0.121306</td>\n",
       "      <td>-0.010089</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>-0.008289</td>\n",
       "      <td>-0.043293</td>\n",
       "      <td>-0.127748</td>\n",
       "      <td>-0.127939</td>\n",
       "      <td>-0.074941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.149772</td>\n",
       "      <td>0.109539</td>\n",
       "      <td>0.090114</td>\n",
       "      <td>0.118735</td>\n",
       "      <td>-0.021739</td>\n",
       "      <td>-0.095942</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.143584</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024626</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>0.148624</td>\n",
       "      <td>-0.060887</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>-0.044135</td>\n",
       "      <td>-0.004543</td>\n",
       "      <td>-0.088525</td>\n",
       "      <td>-0.022525</td>\n",
       "      <td>-0.055222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.116164  0.150140  0.157637  0.167075 -0.038732 -0.195063 -0.037403   \n",
       "1  0.161522  0.152545  0.123183  0.146035 -0.009645 -0.130634  0.002202   \n",
       "2  0.151950  0.117054  0.097127  0.124619 -0.027188 -0.105692  0.009686   \n",
       "3  0.097068  0.135354  0.151290  0.133517 -0.018089 -0.183336 -0.046367   \n",
       "4  0.149772  0.109539  0.090114  0.118735 -0.021739 -0.095942  0.010114   \n",
       "\n",
       "        7         8         9    ...       490       491       492       493  \\\n",
       "0  0.224993  0.061536  0.028788  ...  0.004375 -0.051435  0.164655 -0.029094   \n",
       "1  0.188009  0.064717  0.047527  ...  0.042883 -0.066830  0.183888 -0.068949   \n",
       "2  0.152977  0.043762  0.030666  ...  0.019984 -0.054562  0.149631 -0.061866   \n",
       "3  0.208999  0.050225  0.008495  ... -0.007296 -0.035852  0.121306 -0.010089   \n",
       "4  0.143584  0.040449  0.030532  ...  0.024626 -0.055909  0.148624 -0.060887   \n",
       "\n",
       "        494       495       496       497       498       499  \n",
       "0  0.072818 -0.037900 -0.047797 -0.140069 -0.112368 -0.064705  \n",
       "1  0.019747 -0.037597 -0.015067 -0.122631 -0.028011 -0.070028  \n",
       "2  0.016582 -0.045131 -0.006541 -0.095804 -0.034160 -0.059227  \n",
       "3  0.085524 -0.008289 -0.043293 -0.127748 -0.127939 -0.074941  \n",
       "4  0.010106 -0.044135 -0.004543 -0.088525 -0.022525 -0.055222  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1,max_df=0.95,ngram_range=(1,3))\n",
    "x=vectorizer.fit_transform(data_df['Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (Tf-Idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1,max_df=0.95,ngram_range=(1,3))\n",
    "x=vectorizer.fit_transform(data_df['Review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(x.toarray(),columns=list(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=data_df['Sentiment']\n",
    "y = np.nan_to_num(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,train_size = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aailiyah</th>\n",
       "      <th>aailiyah pretti</th>\n",
       "      <th>aailiyah pretti good</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandon factori</th>\n",
       "      <th>abandon factori readi</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abil</th>\n",
       "      <th>abil actual</th>\n",
       "      <th>abil actual know</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion time</th>\n",
       "      <th>zillion time away</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zombi movi</th>\n",
       "      <th>zombi movi avoid</th>\n",
       "      <th>zombi student</th>\n",
       "      <th>zombi student back</th>\n",
       "      <th>zombiez</th>\n",
       "      <th>zombiez part</th>\n",
       "      <th>zombiez part hellish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2215 rows Ã— 29806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aailiyah  aailiyah pretti  aailiyah pretti good  abandon  \\\n",
       "823          0                0                     0        0   \n",
       "621          0                0                     0        0   \n",
       "1172         0                0                     0        0   \n",
       "1646         0                0                     0        0   \n",
       "2733         0                0                     0        0   \n",
       "...        ...              ...                   ...      ...   \n",
       "2284         0                0                     0        0   \n",
       "799          0                0                     0        0   \n",
       "2382         0                0                     0        0   \n",
       "468          0                0                     0        0   \n",
       "1154         0                0                     0        0   \n",
       "\n",
       "      abandon factori  abandon factori readi  abhor  abil  abil actual  \\\n",
       "823                 0                      0      0     0            0   \n",
       "621                 0                      0      0     0            0   \n",
       "1172                0                      0      0     0            0   \n",
       "1646                0                      0      0     1            0   \n",
       "2733                0                      0      0     0            0   \n",
       "...               ...                    ...    ...   ...          ...   \n",
       "2284                0                      0      0     0            0   \n",
       "799                 0                      0      0     0            0   \n",
       "2382                0                      0      0     0            0   \n",
       "468                 0                      0      0     0            0   \n",
       "1154                0                      0      0     0            0   \n",
       "\n",
       "      abil actual know  ...  zillion time  zillion time away  zombi  \\\n",
       "823                  0  ...             0                  0      0   \n",
       "621                  0  ...             0                  0      0   \n",
       "1172                 0  ...             0                  0      0   \n",
       "1646                 0  ...             0                  0      1   \n",
       "2733                 0  ...             0                  0      0   \n",
       "...                ...  ...           ...                ...    ...   \n",
       "2284                 0  ...             0                  0      0   \n",
       "799                  0  ...             0                  0      0   \n",
       "2382                 0  ...             0                  0      0   \n",
       "468                  0  ...             0                  0      0   \n",
       "1154                 0  ...             0                  0      0   \n",
       "\n",
       "      zombi movi  zombi movi avoid  zombi student  zombi student back  \\\n",
       "823            0                 0              0                   0   \n",
       "621            0                 0              0                   0   \n",
       "1172           0                 0              0                   0   \n",
       "1646           1                 1              0                   0   \n",
       "2733           0                 0              0                   0   \n",
       "...          ...               ...            ...                 ...   \n",
       "2284           0                 0              0                   0   \n",
       "799            0                 0              0                   0   \n",
       "2382           0                 0              0                   0   \n",
       "468            0                 0              0                   0   \n",
       "1154           0                 0              0                   0   \n",
       "\n",
       "      zombiez  zombiez part  zombiez part hellish  \n",
       "823         0             0                     0  \n",
       "621         0             0                     0  \n",
       "1172        0             0                     0  \n",
       "1646        0             0                     0  \n",
       "2733        0             0                     0  \n",
       "...       ...           ...                   ...  \n",
       "2284        0             0                     0  \n",
       "799         0             0                     0  \n",
       "2382        0             0                     0  \n",
       "468         0             0                     0  \n",
       "1154        0             0                     0  \n",
       "\n",
       "[2215 rows x 29806 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] alpha=0.2 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................ alpha=0.2, total=   1.8s\n",
      "[CV] alpha=0.2 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................ alpha=0.2, total=   2.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................................ alpha=0.2, total=   2.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................................ alpha=0.2, total=   1.8s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................................ alpha=0.2, total=   1.8s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   1.8s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   1.8s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   1.6s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   1.6s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   3.7s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   3.2s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   3.3s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   2.7s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   2.9s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   2.3s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   2.6s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   3.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   2.4s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   2.2s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   2.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   2.6s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   2.8s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   5.1s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   4.3s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = { 'alpha':[0.2,0.4,0.6,0.8,1] }\n",
    "grid = GridSearchCV(MultinomialNB(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=0.1, penalty=l1, total=   0.2s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.2s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.2s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.1s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   2.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   2.3s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   2.3s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   2.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   1.8s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ C=0.1, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=0.1, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=0.1, penalty=elasticnet, total=   0.1s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=0.1, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=0.1, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.2s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.2s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.1s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   3.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   3.5s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   2.9s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   3.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   2.5s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... C=1, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] .......................... C=1, penalty=elasticnet, total=   0.1s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] .......................... C=1, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] .......................... C=1, penalty=elasticnet, total=   0.1s\n",
      "[CV] C=1, penalty=elasticnet .........................................\n",
      "[CV] .......................... C=1, penalty=elasticnet, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.2s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   4.3s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   4.3s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   3.9s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   4.2s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   4.0s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] ......................... C=10, penalty=elasticnet, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] ......................... C=10, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] ......................... C=10, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] ......................... C=10, penalty=elasticnet, total=   0.1s\n",
      "[CV] C=10, penalty=elasticnet ........................................\n",
      "[CV] ......................... C=10, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=100, penalty=l1 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=100, penalty=l1, total=   0.1s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.1s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.2s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.2s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.1s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   5.3s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   4.8s\n",
      "[CV] C=100, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=100, penalty=l2, total=   5.3s\n",
      "[CV] C=100, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=100, penalty=l2, total=   5.6s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   5.2s\n",
      "[CV] C=100, penalty=elasticnet .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\maria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ C=100, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=100, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=100, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=100, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=100, penalty=elasticnet, total=   0.1s\n",
      "[CV] C=100, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=100, penalty=elasticnet, total=   0.2s\n",
      "[CV] C=100, penalty=elasticnet .......................................\n",
      "[CV] ........................ C=100, penalty=elasticnet, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = { 'penalty':['l1','l2','elasticnet'], 'C':[0.1,1,10,100]}\n",
    "grid = GridSearchCV(LogisticRegression(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=200 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_features=auto, n_estimators=200, total= 1.8min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=200 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_features=auto, n_estimators=200, total= 1.9min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=200, total= 1.9min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=200, total= 1.8min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=200, total= 1.9min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=500, total= 4.6min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=500, total= 4.6min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=500, total= 4.5min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=500, total= 4.8min\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=500, total= 4.7min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, total= 2.0min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, total= 1.9min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, total= 1.8min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, total= 1.8min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=200, total= 1.9min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, total= 4.2min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, total= 4.3min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, total= 4.2min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, total= 4.7min\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=500, total= 4.5min\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, total=  39.2s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, total=  37.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, total=  37.4s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, total=  37.7s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=200 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=200, total=  36.3s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, total= 1.5min\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, total= 1.5min\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, total= 1.5min\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, total= 1.6min\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=500 .............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=500, total= 1.5min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=200, total= 1.9min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=200, total= 1.9min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=200, total= 1.8min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=200, total= 1.8min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=200, total= 1.8min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=500, total= 4.7min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=500, total= 4.7min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=500, total= 5.4min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=500, total= 7.2min\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=500, total= 9.6min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, total=93.8min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, total= 3.6min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, total= 3.7min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, total= 3.7min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=200, total= 3.9min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, total= 7.1min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, total= 7.7min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, total= 7.6min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, total=22.6min\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=500, total= 9.9min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, total= 1.3min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, total= 1.3min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, total= 1.2min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, total= 1.3min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=200 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=200, total= 1.4min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, total= 3.2min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, total= 3.4min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, total= 3.3min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, total= 3.1min\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=500 ..........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=500, total= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 301.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_features': 'auto', 'n_estimators': 500}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [200,500], 'max_features':['auto','sqrt','log2'] ,'criterion':['gini','entropy'] }\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total= 2.4min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total= 2.7min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total= 2.7min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total= 2.8min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total= 2.7min\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total= 2.6min\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total= 2.0min\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total= 1.8min\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total= 2.4min\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total= 2.3min\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total= 1.9min\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=14.9min\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=16.9min\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=16.9min\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=17.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=21.6min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=21.3min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=30.7min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {'C': [0.1,1, 10], 'gamma': [1,0.1],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(svm.SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'crtiterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.85      0.80       284\n",
      "         1.0       0.82      0.72      0.76       270\n",
      "\n",
      "    accuracy                           0.78       554\n",
      "   macro avg       0.79      0.78      0.78       554\n",
      "weighted avg       0.79      0.78      0.78       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = svm.SVC(kernel='sigmoid')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.77      0.79       284\n",
      "         1.0       0.77      0.83      0.80       270\n",
      "\n",
      "    accuracy                           0.80       554\n",
      "   macro avg       0.80      0.80      0.80       554\n",
      "weighted avg       0.80      0.80      0.80       554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81       284\n",
      "         1.0       0.82      0.76      0.79       270\n",
      "\n",
      "    accuracy                           0.80       554\n",
      "   macro avg       0.80      0.80      0.80       554\n",
      "weighted avg       0.80      0.80      0.80       554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.77      0.75       284\n",
      "         1.0       0.74      0.71      0.72       270\n",
      "\n",
      "    accuracy                           0.74       554\n",
      "   macro avg       0.74      0.74      0.74       554\n",
      "weighted avg       0.74      0.74      0.74       554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.87      0.79       284\n",
      "         1.0       0.83      0.64      0.72       270\n",
      "\n",
      "    accuracy                           0.76       554\n",
      "   macro avg       0.77      0.76      0.75       554\n",
      "weighted avg       0.77      0.76      0.75       554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.83      0.76       284\n",
      "         1.0       0.78      0.63      0.70       270\n",
      "\n",
      "    accuracy                           0.73       554\n",
      "   macro avg       0.74      0.73      0.73       554\n",
      "weighted avg       0.74      0.73      0.73       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning)\n",
    "\\\n",
    "\n",
    "models=[MultinomialNB(), LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(),AdaBoostClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    score=cross_val_score(model,X_train,y_train,cv=5)\n",
    "    model.fit(X_train,y_train.ravel())\n",
    "    pred=model.predict(X_test)\n",
    "    print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
